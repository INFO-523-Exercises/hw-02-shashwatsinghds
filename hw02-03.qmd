---
title: "hw02-03"
author: "Shashwat Singh"
format: html
editor: visual
description: "Transforming like a Data Transformer: Using data transformation to correct non-normality in numerical data."
---

# **Transforming like a Data Transformer**

# Required Setup

```{r}
# Sets the number of significant figures to two - e.g., 0.01
options(digits = 2)

# Required package for quick package downloading and loading 
if (!require(pacman))  
  install.packages("pacman")

# Downloads and load required packages
pacman::p_load(dlookr, # Exploratory data analysis
               forecast, # Needed for Box-Cox transformations
               formattable, # HTML tables from R outputs
               here, # Standardizes paths to data
               kableExtra, # Alternative to formattable
               knitr, # Needed to write HTML reports
               missRanger, # To generate NAs
               tidyverse) # Powerful data wrangling package suite
```

# Load and Examine a Data Set

-   Load data and view
-   Examine columns and data types
-   Examine data normality
-   Describe properties of data

```{r}
# Loading the dataset
#setwd("/Users/shashwatsingh/Desktop/DM/hw-02")
#dataset <- read.csv("data/big_tech_stock_prices.csv") 


# Let's load a data set from the diabetes data set
dataset <- read.csv("data/big_tech_stock_prices.csv") |>
  mutate(
    OpenGroup = ifelse(open >= 1 & open <= 10, "LowOpen", 
                       ifelse(open > 10 & open <= 100, "MediumOpen", "HighOpen"))
  )


dataset |>
  head() |>
  formattable()
```

### **Data Normality**

Normal distributions (bell curves) are a common data assumptions for many [hypothesis testing statistics](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing), in particular [parametric statistics](https://en.wikipedia.org/wiki/Parametric_statistics). Deviations from normality can either strongly skew the results or reduce the power to detect a [significant statistical difference](https://en.wikipedia.org/wiki/Statistical_significance).

Here are the distribution properties to know and consider:

-   The mean, median, and mode are the same value.

-   Distribution symmetry at the mean.

-   Normal distributions can be described by the mean and standard deviation.

### **Describing Properties of our Data (Refined)**

#### Skewness

The symmetry of the distribution

See [Introduction 4.3](https://gchism94.github.io/EDA_In_R_Book/intro.html#sec-DistShape) for more information about these values

```{r, error= FALSE}
  dataset |>
  select(open, high, low, close) |>
  describe() |>
  select(described_variables, skewness) |>
  formattable()


```

-   `describes_variables`: name of the column being described

-   `skewness`: skewness

# **Testing Normality (Accelerated)**

-   Q-Q plots

-   Testing overall normality of two columns

-   Testing normality of groups

**Note** that you can also use `normality()` to run Shapiro-Wilk tests, but since this test is not viable at `N < 20`, I recommend Q-Q plots.

------------------------------------------------------------------------

#### Q-Q Plots

Plots of the quartiles of a target data set against the predicted quartiles from a normal distribution.

Notably, `plot_normality()` will show you the logaritmic and skewed transformations (more below)

```{r}
dataset |>
plot_normality(high, low, open)
```

# **Normality within Groups**

Looking within OpenGroup at the subgroup normality

#### Q-Q Plots

```{r}
dataset %>%
  group_by(OpenGroup) %>%
  select(open, close) %>%
  plot_normality()
```

# Transforming Data

Your data could be more easily interpreted with a transformation, since not all relationships in nature follow a linear relationship - i.e., many biological phenomena follow a power law (or logarithmic curve), where they do not scale linearly.

We will try to transform the "close" column with through several approaches and discuss the pros and cons of each.

```{r}
closeMod <- dataset |>
  filter(close > 0)
```

### **Square-root, Cube-root, and Logarithmic Transformations**

Resolving Skewness using `transform()`.

\"sqrt\": [square-root transformation](https://en.wikipedia.org/wiki/Square_root). � **(moderate skew)**

\"log\": [log transformation](https://en.wikipedia.org/wiki/Logarithm). ���(�) **(greater skew)**

\"log+1\": log transformation. ���(�+1). Used for values that contain 0.

\"1/x\": [inverse transformation](https://en.wikipedia.org/wiki/Inverse_function). 1/� **(severe skew)**

\"x\^2\": [squared transformation](https://en.wikipedia.org/wiki/Quadratic_function). �2

\"x\^3\": [cubed transformation](https://en.wikipedia.org/wiki/Cubic_function). �3

We will compare the `sqrt`, `log+1`, `1/x` (inverse), `x^2`, and `x^3` transformations. Note that you would have to add a constant to use the `log` transformation, so it is easier to use the `log+1` instead. You however need to add a constant to both the `sqrt` and `1/x` transformations because they don\'t include zeros and will otherwise skew the results. *This dataset doesn't contain zeroes.*

#### Square-root Transformation

```{r}
sqrtClose <- transform(closeMod$close, method = "sqrt") 

summary(sqrtClose)
```

```{r}
sqrtClose |> 
  plot()
```

#### Logarithmic (+1) Transformation

```{r}
Log1Close <- transform(closeMod$close, method = "log+1") 

summary(Log1Close)
```

```{r}
Log1Close |>
  plot()
```

#### Inverse Transformation

```{r}
InvClose <- transform(closeMod$close, method = "1/x") 

summary(InvClose)
```

```{r}
InvClose|>
  plot()
```

#### Squared Transformation

```{r}
SqrdClose <- transform(closeMod$close, method = "x^2") 

summary(SqrdClose)
```

```{r}

SqrdClose|>
  plot()
```

#### Cubed Transformation

```{r}
CubeClose <- transform(closeMod$close, method = "x^3") 

summary(CubeClose)
```

```{r}
CubeClose|>
  plot()
```

### **Box-cox Transformation**

There are several transformations, each with it\'s own \"criteria\", and they don\'t always fix extremely skewed data. Instead, you can just choose the [Box-Cox transformation](https://en.wikipedia.org/wiki/Box%E2%80%93Cox_distribution) which searches for the the best lambda value that maximizes the log-likelihood (basically, what power transformation is best). The benefit is that you should have normally distributed data after, but the power relationship might be pretty abstract (i.e., what would a transformation of x\^0.12 be interpreted as in your system?..)

```{r}
BoxCoxClose <- transform(closeMod$close, method = "Box-Cox") 

summary(BoxCoxClose)
```

```{r}
BoxCoxClose |>
  plot()
```

## **Produce an HTML Transformation Summary**

```{r, echo=FALSE, eval=FALSE}
transformation_web_report(dataset)
```
